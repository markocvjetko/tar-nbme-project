{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64e5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from augmentation import *\n",
    "from parsing import *\n",
    "from subsampling import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64c35d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_augmented_data(simplified_data_path_in, simplified_augmented_data_path_out, feats_path, augmented_train_path_out, \n",
    "                          patient_notes_path, augmenter, num_augmentations, percentage_to_augment =0.1, min_length=1):\n",
    "    \n",
    "    samples = read_simplified_data(simplified_data_path_in)\n",
    "    df_patient_notes = pd.read_csv(patient_notes_path)\n",
    "    df_new_patient_notes = df_patient_notes.copy()\n",
    "    \n",
    "    tokenizer = CharacterTokenizer()\n",
    "    simplified_data = []\n",
    "    \n",
    "    all_samples = samples[:]\n",
    "    for i, sample in enumerate(samples):\n",
    "        augmented_samples = augment_simplified_data(num_augmentations, percentage_to_augment, augmenter, sample, min_length)\n",
    "        for augmented_sample in augmented_samples:\n",
    "            new_row = pd.DataFrame([[augmented_sample.pn_num, augmented_sample.case_num, augmented_sample.text]], columns=df_new_patient_notes.columns)\n",
    "            df_new_patient_notes = pd.concat([df_new_patient_notes, new_row])\n",
    "        all_samples += augmented_samples\n",
    "        \n",
    "    for i, sample in enumerate(all_samples):\n",
    "        tokens = tokenizer.tokenize(sample.text)\n",
    "        word_locs = []\n",
    "        curr_loc = 0\n",
    "        \n",
    "        for word in tokens:\n",
    "            word_locs.append((curr_loc, curr_loc + len(word)))\n",
    "            curr_loc += len(word)\n",
    "            \n",
    "        simplified_data.append((tokens, word_locs, sample.labels, sample.pn_num, sample.case_num))\n",
    "    \n",
    "    for tokens, locations, labels, pn_num, case_num in simplified_data:\n",
    "        path = simplified_augmented_data_path_out + str(pn_num) + '_' +str(case_num) + '.csv'\n",
    "        save_simplified_data(tokens, locations, labels, path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    df_out = complexify_data(simplified_augmented_data_path_out, feats_path)\n",
    "    df_out.to_csv(augmented_train_path_out + 'dtrain.csv', index=False)\n",
    "    df_new_patient_notes.to_csv(augmented_train_path_out + 'dpatient_notes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10484a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIMPLIFIED_PATH_IN = 'dataset/subset_250/simplified_train/'\n",
    "# SIMPLIFIED_AUGMENTED_PATH_OUT = 'dataset/subset_250/simplified_train_augmented/'\n",
    "# FEATS_PATH = 'dataset/subset_250/features.csv'\n",
    "# AUGMENTED_TRAIN_PATH_OUT = 'dataset/subset_250/train_augmented/'\n",
    "# PATIENT_NOTES_PATH = 'dataset/subset_250/patient_notes.csv'\n",
    "\n",
    "# synonym_wordnet_aug = SynonymAugmenter()\n",
    "# num_aug = 1\n",
    "\n",
    "# stvara novi dataset sastavljenih od primjera SIMPLIFIED_PATH_IN i njihovih augmentiranih inačica \n",
    "# i sprema ga AUGMENTED_TRAIN_PATH_OUT, stvara novi patient_notes.csv koji uključuje augmentirane primjere\n",
    "\n",
    "# create_augmented_data(SIMPLIFIED_PATH_IN, SIMPLIFIED_AUGMENTED_PATH_OUT, FEATS_PATH, AUGMENTED_TRAIN_PATH_OUT, \n",
    "#                       PATIENT_NOTES_PATH, synonym_wordnet_aug, num_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36581a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '/tar-project/'\n",
    "PATIENT_NOTES_PATH = PATH + 'patient_notes.csv'\n",
    "FEATS_PATH = PATH + 'features.csv'\n",
    "SIMPLIFIED_PATH_IN = PATH + '/simplified_train_250_subset/'\n",
    "\n",
    "\n",
    "augmenters = [LwtrAugmenter(SIMPLIFIED_PATH_IN)]\n",
    "percenteges = [0.1, 0.3, 0.5]\n",
    "num_augmented_examples = [1, 3]\n",
    "runs = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db57d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AugmenterType.WORD_LWTR 0.1 1 1\n",
      "AugmenterType.WORD_LWTR 0.1 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stvari nove datasetove i spremi ih u odgovarajući direktorij\n",
    "\n",
    "for augmenter in augmenters:\n",
    "    for percentage in percenteges:\n",
    "        for num in num_augmented_examples:\n",
    "            for run in runs:\n",
    "                print(augmenter.type, percentage, num, run)\n",
    "                \n",
    "                destination = PATH + 'datasets/' + str(type(augmenter).__name__) +'-percent-aug-'+ str(percentage) +'-num-augs-'+ str(num) +'-run-'+ str(run)\n",
    "                \n",
    "                if not os.path.exists(destination):\n",
    "                    os.makedirs(destination)\n",
    "                    \n",
    "                \n",
    "                SIMPLIFIED_AUGMENTED_PATH_OUT = destination + '/simplified_train_augmented/'\n",
    "                AUGMENTED_TRAIN_PATH_OUT = destination + '/train_augmented/'\n",
    "                \n",
    "                if not os.path.exists(SIMPLIFIED_AUGMENTED_PATH_OUT):\n",
    "                    os.makedirs(SIMPLIFIED_AUGMENTED_PATH_OUT)\n",
    "                    \n",
    "                if not os.path.exists(AUGMENTED_TRAIN_PATH_OUT):\n",
    "                    os.makedirs(AUGMENTED_TRAIN_PATH_OUT)\n",
    "                \n",
    "                create_augmented_data(SIMPLIFIED_PATH_IN, SIMPLIFIED_AUGMENTED_PATH_OUT, FEATS_PATH, AUGMENTED_TRAIN_PATH_OUT, PATIENT_NOTES_PATH, augmenter, num, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e33817-4c1a-48d7-b111-39188492f656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
