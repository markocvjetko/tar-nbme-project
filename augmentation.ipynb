{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d5468b-1c36-4678-9747-fb75cd1dcb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('attributes', (227, 237))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "42d790c4-e876-4310-9ab4-cec98702573c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import math\n",
    "from enum import Enum\n",
    "\n",
    "DATA_PATH = 'data/simplified/'\n",
    "\n",
    "class FeatureSequence():\n",
    "    \n",
    "    def __init__(self, feature_num, start_loc, end_loc):\n",
    "        self.feature_num = feature_num\n",
    "        self.start_loc = start_loc\n",
    "        self.end_loc = end_loc\n",
    "\n",
    "class Sample():\n",
    "    \n",
    "    def __init__(self, text, labels, case_num, pn_num):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.case_num = case_num\n",
    "        self.pn_num = pn_num\n",
    "        self.feat_seqs = []\n",
    "        self.update_feat_seqs()\n",
    "        \n",
    "    def update_feat_seqs(self):\n",
    "        self.feat_seq = []\n",
    "        prev_label = self.labels[0]\n",
    "        start_loc = 0\n",
    "        end_loc = 0\n",
    "        for i, label in enumerate(self.labels):\n",
    "            if prev_label != label:\n",
    "                end_loc = i\n",
    "                self.feat_seqs.append(FeatureSequence(prev_label, start_loc, end_loc))\n",
    "                prev_label = label\n",
    "                start_loc = i\n",
    "        end_loc = i\n",
    "        self.feat_seqs.append(FeatureSequence(prev_label, start_loc, end_loc))\n",
    "    \n",
    "    def get_num_word(self):\n",
    "        return len(self.text.split())\n",
    "    \n",
    "    def feat_seq_num(self):\n",
    "        return len(self.feat_seqs)\n",
    "    \n",
    "    def select_random_feat_seqs(self, feature_num=None, min_length=5):\n",
    "        filtered_seqs = [seq for seq in self.feat_seqs if len(seq) >= 5]\n",
    "        if feature_num != None:\n",
    "            filtered_seqs = [seq for seq in filtered_seqs if seq.feature_num == feature_num]\n",
    "        return random.sample(filtered_seqs)   \n",
    "    \n",
    "    def select_random_word(self):\n",
    "        text = ''.join(self.text)\n",
    "        words = text.split()\n",
    "        word = random.choice(words)\n",
    "        loc = text.find(word)\n",
    "        return word, loc\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "\n",
    "class Augmenter_Type(Enum):\n",
    "    WORD = 1\n",
    "    SEQUENCE = 2\n",
    "\n",
    "\n",
    "    \n",
    "def augment(aug_type, augmenter, sample, percentage_to_augment = 0.1):\n",
    "    if aug_type == Augmenter_Type.WORD:\n",
    "        words_to_augment = math.ceil(sample.get_num_word() * percentage_to_augment)\n",
    "        print()\n",
    "        for i in range(words_to_augment):\n",
    "            word, loc = sample.select_random_word()\n",
    "            aug_word = augmenter.augment(word)\n",
    "            print(word, aug_word)\n",
    "            if len(word) < len(aug_word) :\n",
    "                print('adding', len(aug_word) - len(word))\n",
    "                for j in range(len(aug_word) - len(word)):\n",
    "                    sample.labels.insert(loc, sample.labels[loc])\n",
    "            if len(word) > len(aug_word):\n",
    "                print('removing', len(word) - len(aug_word))\n",
    "                for j in range(len(word) - len(aug_word)):\n",
    "                    print('inside')\n",
    "                    sample.labels.pop(loc)\n",
    "            sample.text = sample.text.replace(word, aug_word, 1)\n",
    "        sample.update_feat_seqs()\n",
    "    \n",
    "    \n",
    "def read_simplified_data(path):\n",
    "    \n",
    "    data_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    samples = []\n",
    "    for data_file in data_files:\n",
    "        case_num, pn_num = (int(i) for i in data_file[:-4].split('_'))\n",
    "        df = pd.read_csv(path + data_file)  \n",
    "        tokens = ''.join(df.word.to_list())\n",
    "        labels = df.label.to_list()\n",
    "        samples.append(Sample(tokens, labels, case_num, pn_num))\n",
    "        \n",
    "    return samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1034c0c7-d5c1-406b-aca9-ef810a53f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = read_simplified_data(DATA_PATH)\n",
    "\n",
    "#print(samples[0].text)\n",
    "#for seq in samples[0].feat_seqs:\n",
    "#    print(seq.feature_num, seq.start_loc, seq.end_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0cf2c04f-a926-4ac4-bb58-c0c4eafca691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer. 704\n",
      "cancer.\n"
     ]
    }
   ],
   "source": [
    "sample = samples[0]\n",
    "word, loc = sample.select_random_word()\n",
    "print(word, loc)\n",
    "print(sample.text[loc:(loc + len(word))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "309b2a00-310b-4287-bb4d-7fad3e1dad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56566f77-98cd-4467-910b-24cb67fcc36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = 'asdgs '\n",
    "back_translation_aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "db700804-8e3d-410d-864c-0b9fe188d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/mc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mc/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'asdgs'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "synonym_wordnet_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "synonym_wordnet_aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ee9961c7-9fa9-4502-ac5c-cda79e2476ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedy brown pole walks bar\n",
      "27 27\n",
      "\n",
      "brown robert brown\n",
      "adding 7\n",
      "robert henry m. robert\n",
      "adding 9\n",
      "pole celestial pole\n",
      "adding 10\n",
      "pole terminal\n",
      "adding 4\n",
      "Speedy Speedy\n",
      "Speedy henry m. robert brown celestial terminal walks bar\n"
     ]
    }
   ],
   "source": [
    "text = 'Speedy brown pole walks bar'\n",
    "labels = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0]\n",
    "print(text)\n",
    "print(len(text), len(labels))\n",
    "sample = Sample(text, labels, 1, 1)\n",
    "augment(Augmenter_Type.WORD, synonym_wordnet_aug, sample, 1)\n",
    "print(sample.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "09d7832b-6f90-4853-8952-33703879acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "S 0\n",
      "p 0\n",
      "e 0\n",
      "e 0\n",
      "d 0\n",
      "y 0\n",
      "  0\n",
      "h 1\n",
      "e 1\n",
      "n 1\n",
      "r 1\n",
      "y 1\n",
      "  1\n",
      "m 1\n",
      ". 1\n",
      "  1\n",
      "r 1\n",
      "o 1\n",
      "b 1\n",
      "e 1\n",
      "r 1\n",
      "t 1\n",
      "  1\n",
      "b 1\n",
      "r 1\n",
      "o 1\n",
      "w 1\n",
      "n 1\n",
      "  0\n",
      "c 0\n",
      "e 0\n",
      "l 0\n",
      "e 0\n",
      "s 0\n",
      "t 0\n",
      "i 0\n",
      "a 0\n",
      "l 0\n",
      "  0\n",
      "t 0\n",
      "e 0\n",
      "r 0\n",
      "m 0\n",
      "i 0\n",
      "n 0\n",
      "a 0\n",
      "l 0\n",
      "  0\n",
      "w 2\n",
      "a 2\n",
      "l 2\n",
      "k 2\n",
      "s 2\n",
      "  0\n",
      "b 0\n",
      "a 0\n",
      "r 0\n"
     ]
    }
   ],
   "source": [
    "print(len(sample.text), len(sample.labels))\n",
    "\n",
    "\n",
    "for i, j in zip(sample.text, sample.labels):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "cd43fcb8-26d2-4ffb-8494-c5ccebef154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0, 2]\n"
     ]
    }
   ],
   "source": [
    "lis = [0, 1, 2]\n",
    "print(lis.pop(1))\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf73f7f-9391-44ca-9be8-271ea90e3a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
