{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64e5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from augmentation import *\n",
    "from parsing import *\n",
    "from subsampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64c35d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_augmented_data(simplified_data_path_in, simplified_augmented_data_path_out, feats_path, augmented_train_path_out, \n",
    "                          patient_notes_path, augmenter, num_augmentations, percentage_to_augment = 0.1, min_length=10):\n",
    "    \n",
    "    samples = read_simplified_data(simplified_data_path_in)\n",
    "    df_patient_notes = pd.read_csv(patient_notes_path)\n",
    "    df_new_patient_notes = df_patient_notes.copy()\n",
    "    \n",
    "    tokenizer = CharacterTokenizer()\n",
    "    simplified_data = []\n",
    "    \n",
    "    samples = [samples[1]] # uzimamo samo prvi primjer radi testova (zbog one greške s indeksima)\n",
    "    \n",
    "    for sample in samples:\n",
    "        augmented_samples = augment_simplified_data(num_augmentations, percentage_to_augment, augmenter, sample, min_length)\n",
    "        \n",
    "        for augmented_sample in augmented_samples:\n",
    "            new_row = pd.DataFrame([[augmented_sample.pn_num, augmented_sample.case_num, augmented_sample.text]], columns=df_new_patient_notes.columns)\n",
    "            df_new_patient_notes = pd.concat([df_new_patient_notes, new_row])\n",
    "            \n",
    "            \n",
    "    all_samples = augmented_samples + samples\n",
    "    \n",
    "    for sample in all_samples:\n",
    "        \n",
    "        tokens = tokenizer.tokenize(sample.text)\n",
    "        word_locs = []\n",
    "        curr_loc = 0\n",
    "        \n",
    "        for word in tokens:\n",
    "            word_locs.append((curr_loc, curr_loc + len(word)))\n",
    "            curr_loc += len(word)\n",
    "            \n",
    "        simplified_data.append((tokens, word_locs, sample.labels, sample.case_num, sample.pn_num))\n",
    "    \n",
    "    for tokens, locations, labels, pn_num, case_num in simplified_data:\n",
    "        path = simplified_augmented_data_path_out + str(case_num) + '_' +str(pn_num) + '.csv'\n",
    "        save_simplified_data(tokens, locations, labels, path)\n",
    "        \n",
    "    df_out = complexify_data(simplified_augmented_data_path_out, feats_path)\n",
    "    df_out.to_csv(augmented_train_path_out + 'augmented_train.csv', index=False)\n",
    "    df_new_patient_notes.to_csv(augmented_train_path_out + 'augmented_patient_notes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10484a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SIMPLIFIED_PATH_IN = 'dataset/subset_250/simplified_train/'\n",
    "SIMPLIFIED_AUGMENTED_PATH_OUT = 'dataset/subset_250/simplified_train_augmented/'\n",
    "FEATS_PATH = 'dataset/subset_250/features.csv'\n",
    "AUGMENTED_TRAIN_PATH_OUT = 'dataset/subset_250/train_augmented/'\n",
    "PATIENT_NOTES_PATH = 'dataset/subset_250/patient_notes.csv'\n",
    "\n",
    "synonym_wordnet_aug = SynonymAugmenter()\n",
    "num_aug = 1\n",
    "\n",
    "# stvara novi dataset sastavljenih od primjera SIMPLIFIED_PATH_IN i njihovih augmentiranih inačica \n",
    "# i sprema ga AUGMENTED_TRAIN_PATH_OUT, stvara novi patient_notes.csv koji uključuje augmentirane primjere\n",
    "\n",
    "create_augmented_data(SIMPLIFIED_PATH_IN, SIMPLIFIED_AUGMENTED_PATH_OUT, FEATS_PATH, AUGMENTED_TRAIN_PATH_OUT, \n",
    "                      PATIENT_NOTES_PATH, synonym_wordnet_aug, num_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
